
# ----------------------------------------------------------
# Algal Bloom Clustering and Prediction (2020â€“2025)
# ----------------------------------------------------------
# Uses K-Means clustering to group Utah Lake water quality data
# and predict 2025 daily algal bloom severity.
# ----------------------------------------------------------

import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.impute import SimpleImputer

# LOAD DATA -------------------------------------------------
train = pd.read_csv('UtahLake_2020_2024.csv')
test = pd.read_csv('UtahLake_2025.csv')

#  DEFINE FEATURES ------------------------------------------
# (based on your actual CSV column names)
features = ['Turbidity', 'WT', 'pH', 'SC', 'DissolvedO2', 'ChlorophyllA']

X_train = train[features]
X_test = test[features]

#  CLEAN DATA: IMPUTE MISSING VALUES -------------------------
imputer = SimpleImputer(strategy='mean')
X_train = pd.DataFrame(imputer.fit_transform(X_train), columns=features)
X_test = pd.DataFrame(imputer.transform(X_test), columns=features)

# STANDARDIZE ------------------------------------------------
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# K-MEANS CLUSTERING (K=5) ----------------------------------
kmeans5 = KMeans(n_clusters=5, random_state=42, n_init=10)
train['Cluster_K5'] = kmeans5.fit_predict(X_train_scaled)
test['Cluster_K5'] = kmeans5.predict(X_test_scaled)

# Compute mean cluster statistics
cluster_summary_k5 = train.groupby('Cluster_K5')[features].mean().round(1)

# Add severity labels based on Chlorophyll-A (highest = strongest bloom)
cluster_summary_k5 = cluster_summary_k5.sort_values('ChlorophyllA', ascending=False)
cluster_summary_k5['Algal Bloom Severity'] = ['Very High', 'High', 'Moderate', 'Low', 'Very Low']

print("=== K = 5 Cluster Summary ===")
print(cluster_summary_k5)
print()

# K-MEANS CLUSTERING (K=10) ---------------------------------
kmeans10 = KMeans(n_clusters=10, random_state=42, n_init=10)
train['Cluster_K10'] = kmeans10.fit_predict(X_train_scaled)
test['Cluster_K10'] = kmeans10.predict(X_test_scaled)

cluster_summary_k10 = train.groupby('Cluster_K10')[features].mean().round(1)
print("=== K = 10 Cluster Summary ===")
print(cluster_summary_k10)
print()

#  ADD SITE INFORMATION FOR PREDICTION ------------------------
# Using your actual columns: 'Date' and 'ID'
results_2025 = test[['ID', 'Date', 'Cluster_K5', 'Cluster_K10']]

# Map numeric cluster to severity (based on sorted order)
severity_map_k5 = dict(zip(cluster_summary_k5.index, cluster_summary_k5['Algal Bloom Severity']))
results_2025['Predicted_Severity_K5'] = results_2025['Cluster_K5'].map(severity_map_k5)

# SAVE RESULTS ----------------------------------------------
results_2025.to_csv('UtahLake_2025_Severity_Predictions.csv', index=False)

print(" Prediction complete! File saved: UtahLake_2025_Severity_Predictions.csv")




# Visualization 
# Daily Severity Timeline per Site (Line or Color Plot)
# Purpose: Show how algal bloom severity fluctuates over time for each site.

import pandas as pd
import matplotlib.pyplot as plt

# Load your predictions file
df = pd.read_csv("UtahLake_2025_Severity_Predictions.csv")

# Convert Date column to datetime
df['Date'] = pd.to_datetime(df['Date'])

# Sort by date
df = df.sort_values('Date')

# Define color codes for severity levels
severity_colors = {
    'Very Low': '#99d8c9',
    'Low': '#2ca25f',
    'Moderate': '#feb24c',
    'High': '#f03b20',
    'Very High': '#bd0026'
}

# Plot one figure per site
for site_id, group in df.groupby('ID'):
    plt.figure(figsize=(10,4))
    plt.scatter(group['Date'], group['Predicted_Severity_K5'].map(severity_colors), 
                c=group['Predicted_Severity_K5'].map(severity_colors), s=40)
    plt.title(f'Algal Bloom Severity Over Time (Site {site_id})')
    plt.xlabel('Date (2025)')
    plt.ylabel('Predicted Severity')
    plt.yticks([])
    plt.grid(alpha=0.3)
    plt.tight_layout()
    plt.show()
